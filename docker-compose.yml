
services:
  gpu-test:
    image: pytorch/pytorch:2.2.0-cuda12.1-cudnn8-devel
    environment:
      - NVIDIA_DISABLE_REQUIRE=1
    command: nvidia-smi
    profiles: ["gpu-test"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  ollama-gpu:
    image: ollama/ollama this doesn't have any models
    environment:
      - NVIDIA_DISABLE_REQUIRE=1
    ports:
        - 11434:11434
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
